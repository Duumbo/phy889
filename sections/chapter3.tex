\section{Representations of point groups} % (fold)
\label{sec:Representations of point groups}

Consider a finite group $G$ with elements $g_1,g_2,\dots,g_m$. If a group $\hat{T}$
of linear generators $\hat{T}g_i$ in space $R$ is homomorphic to $G$, then the
group $\hat{T}$ is said to form a representation of $G$.
Homomorphism leads to $\hat{T}g_i\cdot\hat{T}g_k=\hat{T}g_ig_k$. If $R$ is the
$n$-dimensional vector space $R_n$, then any of its elements $x$ can be expanded
in terms of $n$ unit vector $\vb{e}_k$ forming the basis of this space.
\begin{align}
    x&=x_1\vb{e}_1+x_2\vb{e}_2+\dots+x_n\vb{e}_n
\end{align}

The operator $\hat{T}g_i$ will be defined if we specify its effect on each
of the unit vectors $\vb{e}_k$. Suppose that

\begin{align}
    \hat{T}g_i\vb{e}_k&=\sum_{r=1}^nD_{r,k}(g_i)\vb{e}_r.
\end{align}

To each element $g_i$ of our group, we can assign a matrix $\norm{D_{r,k}(g_i)}$.
It is also clear that the unit element of the group can be associated with a unit
matrix, and the inverse elements can be associated with inverse matrices.

Let us show now that for the matrices $D$ we have
\begin{align}
    D(g_i)D(g_j)=D(g_ig_j)
\end{align}
If we apply $\hat{T}g_i$ and $\hat{T}g_j$ successively to the unit vector
$\vb{e}_k$, we obtain
\begin{align}
    \hat{T}g_i\hat{T}g_j\vb{e}_k&=\hat{T}g_i\sum_rD_{r,k}(g_i)\vb{e}_r\\
                                &=\sum_{f,r}D_{r,k}(g_j)D_{f,r}(g_i)\vb{e}_f.
\end{align}
On the other hand
\begin{align}
    \hat{T}g_i\hat{T}g_i\vb{e}_k&=\hat{T}_{g_ig_j}\vb{e}_k\\
                                &=\sum_fD_{f,k}(g_ig_j)\vb{e}_f.
\end{align}
So $D(g_i)D(g_j)=D(g_ig_j)$ is valid. We will show now that the matrices $D(g_i)$
form a representation of order $n$ of the group $G$. The space $R_n$ is the
representation space, and the basis of this space is the basis of the
representation. By operating with $\hat{T}g_i$ on an arbitrary vector $\vb{x}$ of
space $R_n$, we obtain
\begin{align}
    \hat{T}g_i\vb{x}&=\sum_kx_k\hat{T}g_i\vb{e}_k\\
                    &=\sum_{k,r}x_kD_{r,k}(g_i)\vb{e}_r\\
                    &=\sum_rx'_r\vb{e}_r
\end{align}
where $x'_r=\sum_kD_{r,k}(g_i)x_k$. Let us consider now the change in the
representation matrix which occurs when a new basis $\vb{e}'_i$ is taken in the
space $R_n$, where the new basis is related to $\vb{e}_k$ by the linear
transformation
\begin{align}
    \vb{e}'_i&=\sum_k V_{ki}\vb{e}_k\label{star}\\
    \vb{e}_i&=\sum_k\{V^{-1}\}_{k,i}\vb{e}'_k.
\end{align}
Let us now apply $\hat{T}g_i$ to $\vb{e}'_i$ by using (\autoref{star})
\begin{align}
    \hat{T}g_i\vb{e}'_i&=\sum_kV_{ki}\hat{T}g_i\vb{e}_k\\
                       &=\sum_{k,s}V_{k,i}D_{s,k}(g_i)\vb{e}_s\\
                       &=\sum_{k,s,r}V_{k,i}D_{s,k}\{V^{-1}\}_{r,s}\vb{e}'_r\\
                       &=\sum_r \{V^{-1}DV\}_{r,i}\vb{e}'_r
\end{align}
Thus the representation matrices undergo a similar transformation when we
transform to the new basis. The representation by the matrices $V^{-1}DV$ is
equivalent to the representation by matrices $D$. If the representation
matrices are all unitary, the representation is said to be unitary.

\subsection{Examples of representation} % (fold)
\label{sub:Examples of representation}

\begin{itemize}
    \item The trivial representation, which is associated with the unit matrix.
    \item If the group elements are linear transformations, the matrices of these
        transformations themselves form a representation which is isomorphic to
        the group.
\end{itemize}
These are the trivial invariant subgroups.

\subsubsection{Quadratic Form}
Let's consider the derivation of one of the representations of the group
$C$ of matrices of linear transformations of invariables
$x_1,x_2,\dots,x_n$, $x'_i=\sum_kC_{i,k}x_k$. But now we are also going
to consider the quadratic form
\begin{align}
    \sum_{i,k}a_{i,k}x_ix_k\qquad a_{i,k}=a_{k,i}
\end{align}
Transformations of the variables $x_i$ induces a transformation of the
coefficients of this form. If we substitute
$x'_j=\sum_s\{C^{-1}\}_{j,s}x'_s$, we obtain the following quadratic form
\begin{align}
    \sum_{i,k,j,\ell}a_{i,k}\{C^{-1}\}_{i,j}x'_j\{C^{-1}\}_{k,\ell}x'_\ell
    &=\sum_{j,\ell}a'_{j,\ell}x'_jx'_\ell,
\end{align}
where
\begin{align}
    a'_{j,\ell}&=\sum_{i,k}a_{i,k}\{C^{-1}\}_{i,j}\{C^{-1}\}_{k,\ell}
\end{align}
If we use the notation $A=\norm{a_{i,k}}$, we can write down the transformation
rule for the coefficients $a_{i,k}$ in the matrix form $A'=C^{-1}AC$,
where $C^{-1}$ is the transpose of $C$. Let's now apply the
transformations $C_1$ and $C_2$ to $x_1,x_2,\dots,x_n$.
\begin{align}
    A''&=C_2^{-1}A'C_2=C_2^{-1}C_1^{-1}AC_1C_2\\
    A''&=\qty(C_2C_1)^{-1}A\qty(C_2C_1)
\end{align}
Applications of $C_1$ and $C_2$ is equivalent to $C_2C_1$. The
transformation of the coefficients of the \emph{quadratic form}
form themselves a representation.

% subsection Examples of representation (end)

\subsubsection{Schrödinger equation and its eigenfunctions} % (fold)
\label{sub:Schrödinger equation and its eigenfunctions}

Let's consider a quantum mechanical system described by the Schrödinger equation

\begin{align}
    \qty(\frac{-\hbar^2}{2m}\nabla^2+V(\vb{r}))\psi(\vb{r})=E\psi(\vb{r})
\end{align}
We shall assume that the symmetry group for this system consists of orthogonal
transformation $u_s$, defined by
\begin{align}
    \vb{r}'=u_s\vb{r}\\
    \vb{r}=u_s^{-1}\vb{r}'
\end{align}
Since the laplace operator is invariant under any orthogonal transformation of
coordinates, this yields to
\begin{align}
    \qty(-\frac{\hbar^2}{2m}\nabla^2+V\qty(u_s^{-1}\vb{r}))\psi(u_s^{-1}\vb{r})=E\psi
    \qty(u_s^{-1}\vb{r})
\end{align}
Moreover since the Schrödinger equation is invariant under the $u_s$ transformation
we must have
\begin{align}
    V\qty(u_s^{-1}\vb{r})V(\vb{r})
\end{align}
and therefore, the transformed wave-function
\begin{align}
    \psi'(\vb{r})&=\hat{T}_{u_s}\psi(\vb{r})=\psi(u_s^{-1}\vb{r})
\end{align}
is also an eigenfunction of the Schrödinger equation with the same eigenvalue.
Let's now consider $\psi_1(\vb{r}),\dots,\psi_k(\vb{r})$, a complete set of
orthonormal eigenfunctions of this equation, corresponding to eigenvalue $E$. We
will see that these functions form a basis of a group representation.
Each of the transformed functions can be written in the form
\begin{align}
    \hat{T}_{u_s}\psi_i(\vb{r})=\psi_i\qty(u^{-1}_s\vb{r})=\sum_{j=1}^kD_{j,k}
    (u_s)\psi_j(\vb{r})
\end{align}
$\hat{T}_{u_s}\psi_i(\vb{r})$ must also be orthonormal, since a change of the variables through an orthonormal transformation conserves the
orthonormalisation condition.
\begin{align}
    \int\psi_i(u_s\vb{r}')\psi_j(u_s\vb{r}')\dd{\vb{r}}=
    \int\psi_i(\vb{r})\psi_j(\vb{r})\dd{\vb{r}}
\end{align}
Matrices $\norm{D_{i,j}(u_s)}$ should be unitary, and hence, to each
transformation $u_s$ form the symmetry group of the Schrödinger equation, we
can assign a unitary matrix of order $k$. Let us consider $u_s$ and $u_t$ to be
transformations in the group. Their successive applications
\begin{align}
    \hat{T}_{u_s}\hat{T}_{u_t}\psi_i(\vb{r})&=
    \hat{T}_{u_s}\psi_i(u^{-1}_t\vb{r})\\
                                            &=\psi_i(u^{-1}_tu^{-1}_s\vb{r})\\
                                            &=\psi_i\qty((u_su_t)^{-1}\vb{r})\\
                                            \sum_{\ell=1}^kD_{\ell,\ell}(u_su_t)\psi_\ell(\vb{r}).
\end{align}
On the other hand
\begin{align}
    \hat{T}_{u_s}\hat{T}_{u_t}\psi_i(\vb{r})&=\hat{T}_{u_s}\sum_{j=1}^kD_{j,i}(u_t)\psi_j(\vb{r})\\
                                            &\sum_{j=1}^kD_{j,i}(u_t)\sum_{\ell=1}^kD_{\ell,j}(u_s)\psi_\ell(\vb{r})\\
                                            &=\sum_{\ell=1}^k\{D(u_s)D(u_t)\}_{\ell,i}\psi_\ell(\vb{r}).
\end{align}
$\implies\ $ With each energy eigenvalue, we can associate a representation and
establish the possible types of symmetry of the wave functions without
explicitly solving the Schrödinger equation.
% subsection Schrödinger equation and its eigenfunctions (end)

\subsection{Existence of an equivalent unitary representation} % (fold)
\label{sub:Existance of an equivalent unitary representation}

We shall show that any representation of a finite group is equivalent to a
unitary representation.
Suppose that we have a representation $D$ of the group $G$ consisting of the
elements $g_1,g_2,\dots,g_m$. We regard the representation matrices $D(g_i)$
as the transformation matrices in a $n$-dimensionnal space $R_n$
$\vb{x}(x_1,x_2,\dots,x_n)$ and $\vb{y}(y_1,y_2,\dots,y_n)$ are vectors in this space.
The scalar product will be defined
\begin{align}
    (\vb{x},\vb{y})=x_1y_1+x_2y_2+\dots+x_ny_n
\end{align}
and $D(g_i)$ transforms the vector $\vb{x}$ into the vector $\vb{x}^{(i)}$
\begin{align}
    \vb{x}^{(i)}=D(g_i)\vb{x}\\
    x_\alpha^{(i)}=\sum_\beta D_{\alpha,\beta}(g_i)x_\beta.
\end{align}
Let's suppose that $D(g_i)$ is not unitary, and it does not conserve the scalar
product. We shall show that it is possible to choose a new basis in $R_n$ such
that the transformation matrices for vector components will be unitary.
We take the average of the scalar product over the group and construct the
expression
\begin{align}
    \sum_{i=1}^m\qty(D(g_i)\vb{x},D(g_i)\vb{y})&=\sum_{i=1}^m\qty(\vb{x}^{(i)},\vb{y}^{(i)}).
\end{align}
This can be written as
\begin{align}
    \sum_{i=1}^m(\vb{x}^{(i)},\vb{y}^{(i)})=\qty(L\vb{x},L\vb{y})
\end{align}
where $L$ is a linear transformation.
\begin{align}
    \sum_{i=1}^m\qty(D(g_i)\vb{x},D(g_i)\vb{y})=\qty(\sum_{i=1}^mD^\dagger(g_i)D(g_i)\vb{x},\vb{y})
\end{align}
The matrix $D^\dagger(g_i)D(g_i)$ is Hermitian, and it can be reduced to a
diagonal form through a unitary transformation V
\begin{align}
    d&=V^{-1}\sum_{i=1}^mD^\dagger(g_i)D(g_i)V.
\end{align}
If we substitute $D(g_i)=V^{-1}D(g_i)V$, we can write
\begin{align}
    d&=\sum_{i=1}^mV^{-1}D^\dagger(g_i)VV^{-1}D(g_i)V\\
     &=\sum_{i=1}^m\widetilde{D}^\dagger(g_i)\widetilde{D}(g_i)
\end{align}
and the diagonal elements of the matrices $d$ are given by
\begin{align}
    d_{\alpha,\alpha}&=\sum_{i=1}^m\sum_{\beta=1}^n\widetilde{D}^{\dagger}_{\alpha,\beta}(g_i)\widetilde{D}_{\alpha,\beta}(g_i)\\
                     &=\sum_{i=1}^m\sum_{\beta=1}^n\abs{\widetilde{D}_{\alpha,\beta}(g_i)}^2.
\end{align}
Let us now determine the diagonal matrix $d^{1/2}$, whose  elements are
$\{d^{1/2}\}_{\alpha,\alpha}=\sqrt{d_{\alpha,\alpha}}$.
So $d^{1/2}d^{1/2}=d$ and if we use the self = conjoint property of $d^{1/2}$, we
have
\begin{align}
    \sum_{i=1}^m\qty(\vb{x}^(i),\vb{y}^(i))&=\qty(VdV^{-1}\vb{x},\vb{y})\\
                                           &=\qty(d^{1/2}d^{1/2}V^{-1}\vb{x},V^{-1}\vb{y})\\
                                           &=\qty(d^{1/2}V^{-1}\vb{x},d^{1/2}V^{-1}\vb{y}).
\end{align}
We can go to
\begin{align}
    \qty(L\vb{x},L\vb{y})\rightarrow L=d^{1/2}V^{-1}.
\end{align}
We can also show that the representation of $G$ given by the matrices $LDL^{-1}$
is unitary. For an arbitrary element $g_k$ of $G$,
\begin{align}
    \qty(LD(g_k)\vb{x},LD(g_k)\vb{y})=\qty(L\vb{x},L\vb{y}).
\end{align}
Prove it for next class.

% subsection Existance of an equivalent unitary representation (end)

\subsection{Reducible and irreducible representations} % (fold)
\label{sub:Reducible and irreducible representations}

Suppose that a representation $D$ of the group $G$ is given in a space $R_n$. If
in the space $R_n$ there is a subspace $R_k$, with $k<n$, which is invariant
under all transformations $D$, i.e., if for $x\in R_k$ we have a $D_x\in R_k$,
the representation is \emph{reducible}. Let us take the first $k$ unit vectors
in the space $R_n$ as the unit vectors of the subspace $R_k$. The representation
matrix must have the following form:
\begin{align}
    \mqty(D_{11} & D_{12} & \dots & D_{jk} & D_{1 k+1} & \dots & D_{1n}\\
    \vdots & \vdots & \ddots & \vdots & \vdots & \ddots & \vdots \\
    D_{k1} & D_{k2} & \dots & D_{kk} & D_{kk+1} & \dots & D_{kn}\\
    0 & \dots & \dots & 0 & D_{k+1 k+1} & \dots & D_{k+1n}\\
    \vdots & \vdots & \ddots & \vdots & \vdots & \ddots & \vdots\\
    0 & \dots & \dots & 0 & D_{nk+1} & \dots &D_{nn}
    )
\end{align}

If on the other hand we cannot define an invariant subspace in $R_n$,
the representation is \emph{irreducible}. We shall show that if a reducible
representation $D$ is unitary, the orthogonal complement of the subspace $R_k$,
which we denote $R_{a-k}$, is also invariant under the transformation of $D$.

Let us consider $x\in R_k,y\in R_{n-k}$ and $(x,y)=0$. Since the subspace $R_k$
is invariant $(D_g(x),y)=0)$, but as we know

\begin{align}
    \qty(D(g)x,y)&=\qty(x,D^\dagger(g)y)=(x,D^{-1}(g)y)\\
                 &=(x,D(g^{-1})y)=0\label{starrr},
\end{align}
and hence $D(g^{-1})y\in R_{n-k}$. When $g$ runs over the entire group,
the inverse element $g^{-1}$ will also do so. So (\autoref{starrr}) is satisfied
for all matrices of the representation in question, and the invariance $R_{n-k}$
is proved.

If we take the unit vectors of the subspace $R_k$, as the first $k$ vectors, and
the remaining $n-k$ unit vectors as the vectors of the subspace $R_{n-k}$, the
representation matrix will be quasi-diagonal.

\begin{align}
    \mqty(D_{11} & D_{12} & \dots & D_{jk} & 0 & \dots & 0\\
    \vdots & \vdots & \ddots & \vdots & \vdots & \ddots & \vdots \\
    D_{k1} & D_{k2} & \dots & D_{kk} & 0 & \dots & 0\\
    0 & \dots & \dots & 0 & D_{k+1 k+1} & \dots & D_{k+1n}\\
    \vdots & \vdots & \ddots & \vdots & \vdots & \ddots & \vdots\\
    0 & \dots & \dots & 0 & D_{nk+1} & \dots &D_{nn}
    )
\end{align}

If the space $R$ can be resolved into invariant subspaces, in each of them an
irreducible representation is realised, then the representation $D$ is
\emph{fully reducible}. With a suitable choice of unit vectors, the matrix of
this representation is block diagonal. From this discussion, it follows that

\begin{itemize}
    \item A unitary representation of a group is always irreducible or fully
        reducible.
    \item Any representation of a finite group is either again irreducible or
        fully reducible.
\end{itemize}

If a representation $D$ is reducible, its matrices can be reduced to a
quasi-diagonal form by going under the new system of unit vectors.
We note that in this case, the representation matrices undergo the similarity
transformation: $D\rightarrow V^{-1}DV$, where $V$ is the unitary matrix relating
the unit vectors of the old and new basis.

A representation $D$ is reducible if there exists a non-singular matrix $V$
such that $V^{-1}DV$ is block-diagonal.

% subsection Reducible and irreducible representations (end)
\subsection{Schur's First Lemma} % (fold)
\label{sub:Schur's First Lemma}

\begin{epigraph}
    A matrix which commutes with all the matrices of an irreducible\\
    representation is a multiple of the unit matrix.
\end{epigraph}

Let $D(y)$ represent the matrices of an irreducible representation of order $n$
of the group $G$, $g\in G$. Let's suppose the matrix $M$ commutes with all the
matrices  $D(g)MD(g)=D(g)M$. Let $R_n$ represent the space in which $D(g)$ is
realised. In this space, there should at least be one eigenvector of $M$, we
denote it $x$, such that $M\bar{x}=\lambda\bar{x}$. If we apply the transformation with the representation matrix $D(g)$ to the vector $x$ will have that
\begin{align}
    D(g)\bar{x}=\bar{x}g.
\end{align}
This resulting vector is also an eigenvector of $M$ with the same eigenvalue
$\lambda$.
\begin{align}
    M\bar{x}_g&=MD(g)x=\lambda D(g)\bar{x}\\
              &=\lambda\bar{x}_g.
\end{align}
It follows that the space of eigenvectors of the matrix $M$ corresponding to
the same eigenvalue is invariant under the transformation $D(g)$. But since $D(g)$
is irreducible, it follows that this subspace should coincide with the entire
$R_n$, and the matrix $M$ multiplying by any vector of the space $R_n$ by
$\lambda$, should be of the form
\begin{align}
    M=\mqty(\lambda&\dots&0\\0&\ddots&0\\0&\dots&\lambda)
\end{align}
If a representation is fully reducible, i.e., its matrices have the quasi-diagonal
form, one will always find a matrix which is not a multiple of the unit matrix
and which commutes with all the matrices of this representation. Once we verify
that this matrix can be taken to be the diagonal matrix in which diagonal element
corresponding to the different blocks are not equal to one another.
% subsection Schur's First Lemma (end)

\subsection{Schur's Second Lemma} % (fold)
\label{sub:Schur's Second Lemma}
\begin{theorem}
    Let $D^{(1)}(g)$ and $D^{(2)}(g)$ be the matrices of two irreducible non-equivalent
    representations of a group $G$ of order $n_1$ and $n_2$, respectively. Then, any
    rectangular matrix $M$ with $n_1$ columns and $n_2$ rows which satisfies this
    equation
    \begin{align}
        MD^{(1)}(g)=D^{(2)}(g)M,\qquad\forall g\in G
    \end{align}
    is a null matrix.
\end{theorem}

\begin{proof}
Let us take the Hermitian conjugate on both sides
\begin{align}
    D^{(1)\dagger}(g)M^\dagger=M^\dagger D^{(2)\dagger}(g)
\end{align}
$D^{(1)}(g)$ and $D^{(2)}(g)$ are unitary.
\begin{align}
    D^{(1)-1}(g)M^\dagger=M^\dagger D^{(2)-1}(g)\\
    D^{(1)}(g^{-1})M^\dagger=M^\dagger D^{(2)}(g^{-1})\label{starr}
\end{align}
If $g$ runs over the entire group, then $g^{-1}$ also does so, which lets us
re-write (\autoref{starr}) as
\begin{align}
    D^{(1)}(g)M^\dagger=M^\dagger D^{(2)}(g).
\end{align}
Let's multiply both sides on the left by the matrix $M$.
\begin{align}
    MD^{(2)}M^\dagger&=MM^\dagger D^{(2)}(g)\\
    D^{(2)}(g)MM^\dagger&=MM^\dagger D^{(2)}(g)
\end{align}
According to Schur's first lemma, we conclude that $MM^\dagger$ must be a
multiple of the unit matrix.
\begin{align}
    MM^\dagger&=\lambda E_{n_2}
\end{align}
\begin{description}
    \item[Case 1: $n_1=n_2$]
    In this case, $M$ must be singular $\det M=0$.
    If this was not the case, the $MD^{(2)}(g)=D^{(2)}(g)M$ should yield the
    condition for the equivalence of the representation
    \begin{align}
        D^{(1)}=M^{-1}D^{(2)}M.
    \end{align}
    But this would mean $D^{(1)}$ and $D^{(2)}$ are isomorphic, which is not true
    by hypothesis. $M$ cannot be invertible $\implies\det M=0$.
    If we take
    \begin{align}
        MM^\dagger=\lambda E_{n_2}\\
        \lambda=\sum_j M_{ij}\bar{M}_{ij}\\
        \det M\det M^\dagger=\lambda^{n_2}\\
        \lambda=0=\sum_j\abs{M_{ij}}^2\implies M_{ij}=0
    \end{align}
\item[Case 2: $n_2>n_1$]
    In this case, we augment the matrix $M$ so that it becomes a
    square matrix with $n_2n_1$ rows and columns. We do the same to $M^\dagger$.
    If we denote the two matrices $\widetilde{M}$ and $\widetilde{M}^\dagger$,
    \begin{align}
        \widetilde{M}\widetilde{M}^\dagger = \lambda E_{n_2}\\
        \det\widetilde{M}^\dagger=\det\widetilde{M}=0\implies M_{ij}=0.
    \end{align}
\end{description}
\end{proof}

% subsection Schur's Second Lemma (end)

\subsection{Orthogonality relations of matrix elements of irreducible representation} % (fold)
\label{sub:Orthogonality relations of matrix elements of irreducible representation}

We are going to use Schur's first lemma to establish relations between matrix
elements of irreducible representations. Let $D^{(i)}(g)$ and $D^{(j)}(g)$ be
the matrices of $2$ irreducible non-equivalent unitary representations of a group
$G$ consisting of $m$ elements, with $n_i$ and $n_j$ being the orders of the
representations. We can show that the following relationship between the elements
of $D^{(i)}(g)$ and $D^{(j)}(g)$ exists.
\begin{align}
    \sum_{g\in G}D^{(i)}_{\mu\nu}(g)\bar{D}^{(j)}_{\alpha\beta}(g)&=0\qquad i\neq j\\
    \sum_{g\in G}D^{(i)}_{\mu\nu}(g)\bar{D}^{(i)}_{\alpha\beta}(g)&=\frac m{n_i}
    \delta_{\mu\alpha}\delta_{\nu\beta}
\end{align}

\begin{proof}
    Let's consider the matrix $M$
    \begin{align}
        M&=\sum_{g\in G}D^{(i)}(g)XD^{(j)}(g^{-1}),
    \end{align}
    with $X$ being an arbitrary matrix. We can prove that
    \begin{align}
        D^{(i)}M&=MD^{(j)}\\
        D^{(i)}(g')M&=D^{(i)}(g')\qty(\sum_{g\in G}D^{(i)}(g)XD^{(j)}(g^{-1}))\\
                    &=\sum_{g\in G}D^{(i)}(g')D^{(i)}(g)XD^{(j)}(g^{-1})D^{(j)}
                    (g'^{-1})D^{(j)}(g')\\
                    &=\sum_{g\in G}D^{(i)}(g'')XD^{(j)}(g''^{-1})\\
                    &=MD^{(j)}(g').
    \end{align}
    It follows from Schur's second lemma that $M$ is a null matrix,
    \begin{align}
        M_{\mu\alpha}&=\sum_{g\in G}\sum_{s,k}D^{(i)}_{\mu s}(g)X_{sk}D^{(j)}_{k\alpha}(g^{-1})=0.
    \end{align}
    Since $X$ is an arbitrary matrix, we can set $X_{sk}=1$ if $s=\nu$ and
    $k=\beta$ and $X_{sk}=0$ for all the other values. Then we have
    \begin{align}
        \sum_{g\in G}D^{(i)}_{\mu\nu}(g)D^{(i)}_{\alpha\beta}(g^{-1})=0.
    \end{align}
    Let us now prove the second orthogonality relation and consider the matrix
    \begin{align}
        N&=\sum_{g\in G}D^{(i)}(g)XD^{(i)}(g).
    \end{align}
    In the same way as before, we can show that it commutes with all the matrices
    of the irreducible representation $D^{(i)}$. Consequently, by Schur's first
    lemma, $N$ is a multiple of the identity.
    \begin{align}
        N_{\mu\alpha}&=\sum_{g\in G}\sum_{s,k}D^{(i)}_{\mu s}(g)X_{sk}D^{(i)}_{k\alpha}(g^{-1})\\
                     &=\lambda\delta_{\mu\alpha}
    \end{align}
    Let us now select $X$, such that the only non-zero element is $X_{\nu\beta}=1$.
    The corresponding constant will be denoted by $\lambda_{\nu\beta}$, and we
    obtain
    \begin{align}
        \sum_{g\in G}D^{(i)}_{\mu\nu}(g)D^{(i)}_{\beta\alpha}(g^{-1})&=\lambda_{\nu\beta}\delta_{\mu\alpha}
    \end{align}
    To determine $\lambda_{\nu\beta}$, we substitute $\mu=\alpha$ into this
    equation and then take the sum of both sides over $\mu$ between $1$ and $n_i$.
    \begin{align}
        \sum_{g\in G}\sum_\mu D^{(i)}_{\mu\nu}(g)D^{(j)}_{\beta\nu}(g^{-1})&=
        \lambda_{\nu\beta}n_i\\
        \sum_{g\in G}D^{(i)}_{\beta\nu}(E)=\delta_{\nu\beta}m&=
        \lambda_{\nu\beta}n_i\\
        \implies\ \lambda_{\nu\beta}&=\delta_{\nu\beta}\frac m{n_i}
    \end{align}
    and therefore
    \begin{align}
        \sum_{g\in G}D^{(i)}_{\mu\nu}(g)D^{(i)}_{\beta\alpha}(g^{-1})=
        \delta_{\mu\alpha}\delta_{\nu\beta}\frac m{n_i}\\
        \sum_{g\in G}D^{(i)}_{\mu\nu}(g)D^{(j)}_{\alpha\beta}(g)=\frac m{n_i}
        \delta_{ij}\delta_{\mu\alpha}\delta_{\alpha\nu}
    \end{align}
\end{proof}

For example, the vector $D^{(i)}_{\mu\nu}$ has the components
$D^{(i)}_{\mu\nu}(g_1),D^{(i)}_{\mu\nu}(g_2),\dots$
The number of such vectors which corresponds to one irreducible representation,
$D^{(i)}$, is $n_i^2$. The total number of orthonormal vectors is $\sum_i n_i^2$,
where the sum is evaluated over the non-equivalent irreducible representation.
Because of the orthogonality relations, all these vectors should be linearly
independent. Since the number of linearly independent vectors cannot exceed the
dimensionality of the vector space, it follows that $\sum_i n_i^2\leq m$.
We have deduced that the number of different irreducible representations of a
finite group is finite.

% subsection Orthogonality relations of matrix elements of irreducible representation (end)

\subsection{Characters of representations} % (fold)
\label{sub:Characters of representations}

The character of a representation $D(g)$ is defined as the following function
of the group elements
\begin{align}
    \chi(g)&=\sum_i D_{ii}(g)=S_p D(g)
\end{align}
Let us consider some properties of the characters.
\begin{enumerate}
    \item Equivalent representations have identical characters, since the
        trace of a matrix is invariant under the similarity transformations and
        \begin{align}
            S_p V^{-1}D(g)V&=S_p D(g).
        \end{align}
    \item The characters of the representation matrices corresponding to =
        the elements of a given class are identical.
    \item The characters of the irreducible representations have the orthogonality 
        property
        \begin{align}
            \sum_{g\in G}\chi^{(i)}(g)\bar{\chi}^{(j)}(g)&=m\delta_{ij},
        \end{align}
        with $\chi$ and $\bar{\chi}$ being characters of $D$.
\begin{proof}
    From 1, it is sufficient to prove it for unitary representations. We know
    that
    \begin{align}
        \sum_{g\in G}D^{(i)}_{\mu\mu}(g)D^{(j)}_{\alpha\alpha}(g)&=\frac m{n_i}
        \delta_{ij}\delta_{\alpha\mu}\\
        \sum_{g\in G}\chi^{(i)}(g)\chi^{(j)}(g)&=\frac m{n_i}n_i\delta_{ij}=m\delta_{ij}.
    \end{align}
    The function $\chi(g)$ has the same value for all the elements of a given
    class
    \begin{align}
        \sum_s k_s\chi_s^{(i)}\bar{\chi}_s^{(j)}&=m\delta_{ij},
    \end{align}
    with $k_s$ the number of elements in the class $C_s$, and $\chi_s^{(i)}$ is
    the value of the character of the representation corresponding to the element
    of this class.
\end{proof}
\item The character of a \emph{reducible} representation $D$ is equal to the sum
    of characters of irreducible representation into which it can decompose. To
    show this, we recall the quasi-diagonal form of the reducible representations
    and also using 1. If we denote the characters of a reducible representation
    by $\chi(g)$, then
    \begin{align}
        \chi(g)&=\sum_j r_j\chi^{(j)}(g),
    \end{align}
    where $r_j$ shows how many times the irreducible representation $D^{(j)}$
    enters the decomposition of the reducible one.
    From the orthogonality relations, we can establish
    \begin{align}
        r_j&=\frac1m\sum_{g\in G}\bar{\chi}^{(j)}(g)\chi^{(j)}(g)
    \end{align}
    The decomposition of a reducible representation into irreducible parts can be
    carried out uniquely. Symbolically, it is written
    \begin{align}
        D&=\sum_j{}^{\oplus}r_jD^{(j)}
    \end{align}
\end{enumerate}



% subsection Characters of representations (end)

\begin{exercise}
    Prove that any representation of a simple group (one without a normal divisor)
    is isomorphic to the group
    itself.
\end{exercise}

\begin{exercise}
    Use Schur's first lemma to show that all irreducible representations of an
    Abelian group are of order $1$.
\end{exercise}

\begin{exercise}
    Use Schur's first lemma to show that the sum of irreducible representation
    matrices corresponding to the elements of a given class is a multiple of the
    unit matrix.
\end{exercise}

\begin{exercise}
    Construct the matrices of the irreducible representation of $S_3$.
\end{exercise}

\begin{exercise}
    Show that if two elements of a group are mutually inverse, then the
    characters of their representations are mutually complex conjugate.
\end{exercise}
% section Representations of point groups (end)
